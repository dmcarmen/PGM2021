{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Models – Spring 2021\n",
    "## First Course Exam, March 12.3.2021 9.00-11.30\n",
    "\n",
    "<span style=\"color:red\">**Carmen Diez 015380485**</span>\n",
    "\n",
    "### Instructions\n",
    "Make sure the notebook produces correct results when ran sequentially starting from the first cell. You can ensure this by clearing all outputs (`Edit > Clear All Outputs`), running all cells (`Run > Run All Cells`), and finally correcting any errors.\n",
    "\n",
    "-Submit this notebook containing your derivations to Moodle.\n",
    "\n",
    "-The return form will be closed at 11.30 (or a minute later), be sure to submit your answers in time.\n",
    "\n",
    "-Any outside contact during the exam is strictly forbidden.\n",
    "\n",
    "-Points are given only to answers that have all the calculations and justifications returned.\n",
    "\n",
    "-Return any partial solutions, points are awarded for partial solution.\n",
    "\n",
    "-Some questions may benefit from online search, you are permitted to use internet, books and sources -\n",
    "but direct copy-paste from sources is not permitted, and ANY SOURCE YOU USE MUST BE CITED.\n",
    "You can use code from your exercises (if it is needed, cited of course).\n",
    "\n",
    "-You can use any language for the calculations, Python and R are preferred.\n",
    "\n",
    "-The answers will be graded by a person.\n",
    "\n",
    "Return format:\n",
    "\n",
    "-Jupyter notebooks are the preferred format.\n",
    "\n",
    "-Text format is also permitted.\n",
    "\n",
    "-Pdf is also permitted.\n",
    "\n",
    "-Clear photos of clearly hand written answers are also permitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: motivation (6 points)\n",
    "***\n",
    "\n",
    "Why have researchers developed probabilistic graphical models? What problems do they solve and what are the key advantages? Full points can be obtained by three paragraphs, each a detailing clear, separate and non-overlapping advantage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "First, symbolic logic is generally suboptimal for common sense reasoning: too much work to have into account all the factors and attend all the rules, we actually don't know all the factors in general and, because of monocity, logic doesn't let us change our minds. Thanks to probability we can address easilier these problems: we give a probability to a success, not all the factors related to it; and we can use Bayes' formula to adjust the probability if needed.\n",
    "\n",
    "Furthermore, probabilistic graphical methods offered an scenario where many computations were less complex and easy to perform than usual. For example, the algortihms for Belief Propagation and jointrees are a proof for this. Bayesian networks are useful for computations as they define a unique probability distribution over the network variables, they consider some variables and only its direct parents at a time, and, thanks to that, if the number of parents remain small, we only have a polynomial number of probabilities. These properties makes them reliable and easy to handle.\n",
    "\n",
    "\n",
    "Lastly, one of the main reasons to use probabilistic graphical models is that they have been used to help solving real-world problems. There are a lot of uses for them in biology (as the problem of the DNA and RNA we did), text classifiers (also as the problem from week 3), speech recognition, natural language processing...\n",
    "\n",
    "\n",
    "*Answers derived mostly from the course slides.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: statistical independence (6 points)\n",
    "***\n",
    "\n",
    "Give a single concrete probability distribution over three binary random variables X, Y , Z, with properties:\n",
    "\n",
    "(a) The distribution is positive, i.e., all value assignments have probability > 0.\n",
    "\n",
    "(b) X is statistically dependent on Y.\n",
    "\n",
    "(c) Z is statistically dependent on Y.\n",
    "\n",
    "(d) X is statistically independent of Z.\n",
    "\n",
    "Clearly justify that the properties are satisfied EXACTLY in a single distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "$A$ and $B$ are independent if $P(A | B) = P(A)$ (if $P(B) > 0$). The condition can also be expressed as $P(A,B)=P(A)P(B)$.\n",
    "\n",
    "For these properties to hold we want:\n",
    "\n",
    "  (a) $P(X, Y) \\neq P(X)P(Y)$, $P(X | Y) \\neq P(X)$ nor $P(Y | X) \\neq P(Y)$.\n",
    "  \n",
    "  (b) $P(Y, Z) \\neq P(Y)P(Z)$, $P(Y | Z) \\neq P(Y)$ nor $P(Z | Y) \\neq P(Z)$.\n",
    "  \n",
    "  (c) $P(X, Z) = P(X)P(Z)$, $P(X | Z) = P(X)$ and $P(Z | X) = P(Z)$.\n",
    "  \n",
    "And $P( A |B) = \\frac{P(A,B)}{P(B)}$. \n",
    "\n",
    "Thus, $P(X,Y,Z)= P(Y)P(X|Y)P(Z|X,Y)= P(Y)P(X|Y)P(Z|Y)$.\n",
    "\n",
    "We can express these relations with a BN. With the DAG and CPT's the probability distribution is defined. For example the CPTs can be defined by:\n",
    "\n",
    "P(Y=T) = 0.5\n",
    "\n",
    "P(X=T|Y=T) = 0.3\n",
    "\n",
    "P(X=T|Y=F) = 0.6\n",
    "\n",
    "P(Z=T|Y=T) = 0.4\n",
    "\n",
    "P(Z=T|Y=F) = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"188pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 188.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 184,-112 184,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"90\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"90\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- Y&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Y&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76.64,-74.15C68.12,-64.69 56.91,-52.24 47.31,-41.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"49.63,-38.92 40.34,-33.82 44.43,-43.6 49.63,-38.92\"/>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"153\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"153\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "<!-- Y&#45;&gt;Z -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Y&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.36,-74.15C111.88,-64.69 123.09,-52.24 132.69,-41.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.57,-43.6 139.66,-33.82 130.37,-38.92 135.57,-43.6\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f7a761494f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "g = graphviz.Digraph(engine='dot', graph_attr={'rankdir':'TB', 'size':'20', 'nodesep':'1'})\n",
    "\n",
    "g.node(\"X\")\n",
    "g.node(\"Y\")\n",
    "g.node(\"Z\")\n",
    "\n",
    "g.edge(\"Y\", 'Z')\n",
    "g.edge(\"Y\", 'X')\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the distribution can be expressed with a joint distribution table and its unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YXZ\n",
      "FFF:  0.16000000000000003\n",
      "FFT:  0.04000000000000001\n",
      "FTF:  0.24\n",
      "FTT:  0.06\n",
      "TFF:  0.21\n",
      "TFT:  0.13999999999999999\n",
      "TTF:  0.09\n",
      "TTT:  0.06\n"
     ]
    }
   ],
   "source": [
    "#P(X,Y,Z)= P(Y)P(X|Y)P(Z|Y)\n",
    "fff = (1-0.5)*(1-0.6)*(1-0.2)\n",
    "fft = (1-0.5)*(1-0.6)*0.2\n",
    "ftf = (1-0.5)*0.6*(1-0.2)\n",
    "ftt = (1-0.5)*0.6*0.2\n",
    "\n",
    "tff = 0.5*(1-0.3)*(1-0.4)\n",
    "tft = 0.5*(1-0.3)*0.4\n",
    "ttf = 0.5*0.3*(1-0.4)\n",
    "ttt = 0.5*0.3*0.4\n",
    "\n",
    "print('YXZ')\n",
    "print('FFF: ',fff)\n",
    "print('FFT: ',fft)\n",
    "print('FTF: ',ftf)\n",
    "print('FTT: ',ftt)\n",
    "\n",
    "print('TFF: ',tff)\n",
    "print('TFT: ',tft)\n",
    "print('TTF: ',ttf)\n",
    "print('TTT: ',ttt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Bayesian networks (6 points)\n",
    "***\n",
    "\n",
    "Consider the following BN structure. \n",
    "\n",
    "![bn.svg](bn.svg)\n",
    "\n",
    "Answer the following queries and questions.\n",
    "\n",
    "(a) Decide whether the following d-separations hold or not. Justify your answer here in detail. Points only with a solid justification.\n",
    "\n",
    "\n",
    "(a1) D d-separated from F given H, E?\n",
    "\n",
    "(a2) A d-separated from H given B, G?\n",
    "\n",
    "(a3) B d-separated from C given A, E?\n",
    "\n",
    "(a4) D d-separated from  C?\n",
    "\n",
    "(a5) D d-separated from A given H, G?\n",
    "\n",
    "\n",
    "(b) Suppose two nodes X and Y are not adjacent in the DAG structure of a Bayesian network, i.e., there is no arc between them. Show that there is a set S, such that X and Y are d-separated given S. (Hint: You can examine the above network and then formulate a general proof.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "(a1) $D \\mathrel{\\unicode{x2AEB}}_{G} F \\mid H, E$: false, as there is an active path D → F.\n",
    "\n",
    "(a2) $A\\mathrel{\\unicode{x2AEB}}_{G} H \\mid B, G$: false, as there is an active path A → C → E → F → H.\n",
    "\n",
    "(a3) $B\\mathrel{\\unicode{x2AEB}}_{G} C \\mid A, E$: false, as there is an active path B → $E$ ← C.\n",
    "\n",
    "(a4) $D\\mathrel{\\unicode{x2AEB}}_{G} C$: true, as all paths are blocked by  F → H ← G or  D → F ← E.\n",
    "\n",
    "(a5) $D\\mathrel{\\unicode{x2AEB}}_{G} A \\mid H, G$: true, all paths are blocked by A → B → E or  A → C → E.\n",
    "\n",
    "(b) As shown in exercise 2.2, a node in a Bayesian network is conditionally independent of all the other nodes, given its (minimal) Markov blanket (parents, children, spouses (parents of children)). Then, for this scenario, the set S stated is the minimal Markov blanket and X can be the first node and Y the second one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and answer 2 of the following 3 questions. Clearly mark which ones you want to be graded.\n",
    "\n",
    "I want **4** and **5** to be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: naive Bayes classifiers, parameter estimation (6 points, return answers to 2 of the questions 4, 5, and 6)\n",
    "***\n",
    "\n",
    "Suppose W1 and W2 are words that appear commonly in emails. Suppose you have the following dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPAM:\n",
    "\n",
    "-200 emails with W1 and W2\n",
    "\n",
    "-300 emails with W1 but not W2\n",
    "\n",
    "-400 emails with W2 but not W1\n",
    "\n",
    "-900 emails with neither W1 or W2\n",
    "\n",
    "NOT SPAM:\n",
    "\n",
    "-100 emails with W1 and W2\n",
    "\n",
    "-500 emails with W1 but not W2\n",
    "\n",
    "-400 emails with W2 but not W1\n",
    "\n",
    "-800 emails with neither W1 or W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Formulate the Naive Bayes Classifier for classifying mail in to SPAM and not SPAM with words W1 and W2 as the features. Learn the parameters using Laplace smoothing.\n",
    "\n",
    "(b) Using these parameters, what is the probability of the next email being spam, if both words W1 and W2 appear in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Using the same logic as in exercise 3.1 and the formulas from lecture 5.\n",
    "\n",
    "With Laplace Smoothing and assuming parameter sharing.\n",
    "\n",
    "$P(C=c)= \\frac{N_c +1}{N + |dom(C)|}$ and $P(X_j = a | C=c) = \\frac{N_{c,a} +1}{\\sum_{b=1}^{T} N_{c,b} + T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>notSpam</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W1</td>\n",
       "      <td>600</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2</td>\n",
       "      <td>500</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word notSpam spam\n",
       "0   W1     600  500\n",
       "1   W2     500  600"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a\n",
    "NSpam = 200+300+400+900 #Nc c = spam\n",
    "NNotSpam = 100+500+400+800 #Nc c = not spam\n",
    "N = NSpam + NNotSpam #N\n",
    "domC = 2\n",
    "T = 2\n",
    "\n",
    "columns = ['word','notSpam', 'spam']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "df = df.append({'word': 'W1', 'notSpam': 100+500 , 'spam': 200+300}, ignore_index=True)\n",
    "df = df.append({'word': 'W2', 'notSpam': 100+400 , 'spam': 200+400}, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "denomNotSpam = df['notSpam'].sum() + T\n",
    "denomSpam = df['spam'].sum() + T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>notSpam</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W1</td>\n",
       "      <td>0.545372</td>\n",
       "      <td>0.454628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2</td>\n",
       "      <td>0.454628</td>\n",
       "      <td>0.545372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P(C)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word   notSpam      spam\n",
       "0    W1  0.545372  0.454628\n",
       "1    W2  0.454628  0.545372\n",
       "2  P(C)       0.5       0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfProbs = df.copy()\n",
    "for i in df.index:\n",
    "    dfProbs.at[i, 'notSpam'] = (df.at[i, 'notSpam'] + 1)/(denomNotSpam)\n",
    "    dfProbs.at[i, 'spam'] = (df.at[i, 'spam'] + 1)/(denomSpam)\n",
    "dfProbs = dfProbs.append({'word': 'P(C)', 'spam': (NSpam+1)/(N+domC), 'notSpam': (NNotSpam+1)/(N+domC)}, ignore_index=True)\n",
    "dfProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b\n",
    "def PWordCondClass(w, cl):\n",
    "    return dfProbs[dfProbs['word'] == w][cl].item()\n",
    "def PClass(cl):\n",
    "    return dfProbs[dfProbs['word'] == 'P(C)'][cl].item()\n",
    "\n",
    "def PClassCondData(cl, data):\n",
    "    prob = 1\n",
    "    for w in data:\n",
    "        prob = prob*PWordCondClass(w, cl)\n",
    "    return prob*PClass(cl)\n",
    "\n",
    "def posteriorSpam(data):\n",
    "    pSpamCondData = PClassCondData('spam', data)\n",
    "    pNotSpamCondData = PClassCondData('notSpam', data)\n",
    "    \n",
    "    norm = 1/(pSpamCondData+pNotSpamCondData)\n",
    "    print('P(C=Spam|D)=', pSpamCondData*norm)\n",
    "    print('P(C=NotSpam|D)=', pNotSpamCondData*norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(C=Spam|D)= 0.5\n",
      "P(C=NotSpam|D)= 0.5\n"
     ]
    }
   ],
   "source": [
    "#P(C=NotSpam|D)\n",
    "posteriorSpam(['W1', 'W2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: inference, causality (6 points, return answers to 2 of the questions 4, 5, and 6)\n",
    "***\n",
    "\n",
    "Consider the following singly connected Bayesian network.\n",
    "\n",
    "![inference.png](inference.png)\n",
    "\n",
    "(a) Calculate the distribution P(W|X = 0) by factor elimination. You may use any version of the algorithm but you must calculate it yourself, and not use packages. Return all calculations.\n",
    "\n",
    "(b) Calculate the distribution P (W |do(X = 0)). Return all calculations.\n",
    "\n",
    "(c) Is there a difference in the result of (a) and (b) or not? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Elimination tree from which we can perform message passing (as in exercise 6.6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"212pt\" height=\"218pt\"\n",
       " viewBox=\"0.00 0.00 212.08 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-214 208.08,-214 208.08,4 -4,4\"/>\n",
       "<!-- XYWZ, f(X,Z)*f(Y,W) -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>XYWZ, f(X,Z)*f(Y,W)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"102.04\" cy=\"-192\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.04\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\">XYWZ, f(X,Z)*f(Y,W)</text>\n",
       "</g>\n",
       "<!-- YZ, f(Y,Z) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>YZ, f(Y,Z)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"102.04\" cy=\"-105\" rx=\"53.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.04\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">YZ, f(Y,Z)</text>\n",
       "</g>\n",
       "<!-- XYWZ, f(X,Z)*f(Y,W)&#45;&#45;YZ, f(Y,Z) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>XYWZ, f(X,Z)*f(Y,W)&#45;&#45;YZ, f(Y,Z)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.04,-173.8C102.04,-159.05 102.04,-137.92 102.04,-123.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"111.54\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\">YZ</text>\n",
       "</g>\n",
       "<!-- Z, f(Z) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Z, f(Z)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"102.04\" cy=\"-18\" rx=\"39.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"102.04\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Z, f(Z)</text>\n",
       "</g>\n",
       "<!-- YZ, f(Y,Z)&#45;&#45;Z, f(Z) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>YZ, f(Y,Z)&#45;&#45;Z, f(Z)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.04,-86.8C102.04,-72.05 102.04,-50.92 102.04,-36.18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.04\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x7f7a76153490>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "g = graphviz.Graph(engine='dot', \n",
    "                   graph_attr={'rankdir':'TB', \n",
    "                               'size':'7', 'nodesep':'2'})\n",
    "\n",
    "g.node(\"XYWZ, f(X,Z)*f(Y,W)\")\n",
    "g.node(\"YZ, f(Y,Z)\")\n",
    "g.node(\"Z, f(Z)\")\n",
    "\n",
    "g.edge(\"XYWZ, f(X,Z)*f(Y,W)\", \"YZ, f(Y,Z)\", label=\"YZ\")\n",
    "g.edge(\"YZ, f(Y,Z)\", \"Z, f(Z)\", label=\"Z\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multPass(f1, f2):   \n",
    "    nodes = np.unique(list(f1.columns[:-1]) + list(f2.columns[:-1])).tolist()\n",
    "    col1 = f1.columns[-1]\n",
    "    col2 = f2.columns[-1]\n",
    "    \n",
    "    fres = f1.merge(f2, how='left')\n",
    "    fres[col1] = fres[col1]*fres[col2]\n",
    "    fres = fres.drop(columns = col2)\n",
    "    \n",
    "    return fres[nodes+[col1]]\n",
    "\n",
    "def sumOutPass(f1, V): #take V out\n",
    "    if len(V)==0:\n",
    "        return f1\n",
    "    cols = f1.columns[:-1]\n",
    "    colsOut = list(cols[[node not in V for node in cols]])\n",
    "    fres = f1.groupby(colsOut, as_index=False).sum().drop(columns = V)\n",
    "    return fres \n",
    "\n",
    "def projPass(f1, V): #stay with V only\n",
    "    V = list(set(f1.columns[:-1]).difference(set(V)))\n",
    "    return sumOutPass(f1, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$phi1 = f(X,Z)*f(Y,W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: structure learning (6 points, return answers to 2 of the question 4, 5, and 6)\n",
    "***\n",
    "\n",
    "Consider the following local scores (not likelihood equivalent, i.e., members of the same Markov equivalence class may receive different scores). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(1, {}) = 70, f(1, {2}) = 65, f(1, {3}) = 70, f(1, {2, 3}) = 2\n",
    "\n",
    "f(2, {}) = 15, f(2, {1}) = 61, f(2, {3}) = 46, f(2, {1, 3}) = 86\n",
    "\n",
    "f(3, {}) = 30, f(3, {1}) = 8, f(3, {2}) = 78, f(3, {1, 2}) = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dynamic programming algorithm to find (one of) the highest scoring DAG(s). Do not use ready made packages. Return all calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide you answer in cels here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
